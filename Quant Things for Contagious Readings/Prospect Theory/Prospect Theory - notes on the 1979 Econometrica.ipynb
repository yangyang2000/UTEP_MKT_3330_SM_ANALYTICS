{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prospect Theory\n",
    "\n",
    "Perhaps there doesn't exist a more important theory to the way we think about human behavior than Daniel Kahneman and Amos Tverksy's prospect theory, for which the former won the Nobel prize in economics. To read the formal theory, click [here](https://www.dropbox.com/s/uy0w4t84kt77zwy/prospect_theory.pdf?dl=0).\n",
    "\n",
    "To understand the importance of prospect theory, we first have to understand expected utility theory, the predominant framework that economists used to describe decisions under risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick and dirty intro to expected utility theory.\n",
    "\n",
    "As we've discussed in the utility maximization introduction, the concept of utility functions is derived from the axioms of complete and rational preferences. Utility functions map choices onto real numbers such that the largest real number value of a utility function given a set of choices indicates the choice that an individual will pick.\n",
    "\n",
    "Expected utility theory builds on this fundamental understanding of human decision making to extend to decision making under risk.\n",
    "\n",
    "First we define a few key concepts.\n",
    "\n",
    "1. **Prospect**: it is a \"list of tuples\" $[(x_1,p_1);(x_2,p_2);...;(x_n,p_n)]$ that defines a lottery that yields some out come $x_i$ with some *probablity* $p_i$. \n",
    "\n",
    "2. (Objective) **Probability** is defined as having the following standard properties:\n",
    "    1. $\\sum_ip_i=1$ Sum of all outcomes' probabilities add to 1.\n",
    "    2. $0<p_i\\le1\\forall i$ Probability of each outcome must be positive and less than or equal to 1.\n",
    "\n",
    "Thus, a prospect is any distribution over outcomes.\n",
    "\n",
    "The standard expected utility theory incorporates the following 3 tenets:\n",
    "\n",
    "1. **Expectation**: $u([(x_1,p_1);...;(x_n,p_n)])=p_1u(x_1)+...+p_nu(x_n)$ The utility of a lottery is equal to the probability-weighted average of the utility of each possible outcome. If a lottery was 50/50 winning a car (which you value at \\$30000) or a set of [steak knives](https://www.youtube.com/watch?v=wVQPY4LlbJ4) (which you value at \\$100), then your expected utility will be $.5(30000)+.5(100)=\\$15500$.\n",
    "2. **Asset integration**:  $[(x_1,p_1);...;(x_n,p_n)]$ is acceptable at asset position $w$ iff (if and only if) $u([(w+x_1,p_1),...,(w+x_n,p_n)])>u(w).$ This just means the lottery makes you better off, i.e. that the expected utility of having \\$w must be less than the expected utility of having \\$w *and* the lottery. Note $w$ does not have to be money, it can be any current asset (something that gives you utility) holding.\n",
    "3. **Risk aversion**: $u$ is concave, i.e. $u''<0$. This means that having a certain outcome is preferred to having an uncertain outcome with the same objective expected payoff.\n",
    "![risk aversion image](http://slideplayer.com/slide/9701830/31/images/3/Risk+aversion+and+risk+loving..jpg)\n",
    "\n",
    "If you think about expected utility theory, these principles seem to make a lot of sense. Indeed, much of human behavior can be described fairly well using expected utility theory. However, Kahneman and Tversky made a career out of pointing out cases under which expected utility theory does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples that violate expected utility theory\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 33% chance to gain \\$2500 <br/> 66% chance to gain \\$2400<br/>1% chance to get \\$0 | \\$2400 for sure |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "82% of subjects picked B.\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 33% chance to gain \\$2500 <br/> 67% chance to get \\$0 |  34% chance to gain \\$2400 <br/> 66% chance to get \\$0 |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "83% of subjects picked A.\n",
    "\n",
    "According to expected utility theory, if we normalize $u(0)=0$, the first problem's outcome implies:\n",
    "\n",
    "$$\n",
    "u(2400)>.33u(2500)+.66u(2400)\\implies.34u(2400)>.33u(2500)\n",
    "$$\n",
    "\n",
    "The second problem's outcomes implies:\n",
    "\n",
    "$$\n",
    ".33u(2500)>.34u(2400)\n",
    "$$\n",
    "\n",
    "These results are contradictory if expected utility theory holds. The following is another similar demonstration of contradictory preferences following expected utility theory.\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 80% chance of getting 4000| 3000 for sure |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "80% of subjects picked B.\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 20% chance of getting 4000| 25% chance of getting 3000 |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "65% of subjects picked A.\n",
    "\n",
    "To see the contradiction, simply rearrange terms:\n",
    "\n",
    "$$\n",
    ".8u(4000)<u(3000)\\implies.8<u(3000)/u(4000) \\\\\n",
    ".2u(4000)>.25u(3000)\\implies.8>u(3000)/u(4000) \\Rightarrow\\Leftarrow\n",
    "$$\n",
    "\n",
    "Expected utility theory states that if B is preferred to A, then any probaiblty mixture (B,p) must be preferred to (A,p).\n",
    "\n",
    "Kahneman and Tversky demonstrate these violations of expected utility theory further in non-monetary scenarios.\n",
    "\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 50% to win 3 wk tour of England,<br> France and Italy| One week of England, <br>for sure |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "78% of subjects picked B.\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| 5% to win 3 wk tour of England,<br> France and Italy| 10% to win one week of England |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "67% of subjects picked A.\n",
    "\n",
    "Here, we have:\n",
    "$$\n",
    ".5u(E,F,I)<u(E)\\implies.5<u(E)/u(E,F,I)\\\\\n",
    ".05u(E,F,I)>.1u(E)\\implies.5>u(E)/u(E,F,I)\\Rightarrow\\Leftarrow\n",
    "$$\n",
    "\n",
    "It seems from all these examples where we've inserted 1 certain outcome, that certain outcomes have additional \"weights.\" But we do not need a certain outcome to demonstrate violations of expected utility theory. \n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (6000, .45)| (3000, .9) |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "86% of subjects picked B.\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (6000, .001)| (3000, .002) |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "73% of subjects picked A.\n",
    "\n",
    "Here, we have:\n",
    "$$\n",
    ".45u(6000)<.9u(3000)\\implies .5<u(3000)/u(6000)\\\\\n",
    ".001u(6000)>.002u(3000)\\implies.5>u(3000)/u(6000)\\Rightarrow\\Leftarrow\n",
    "$$\n",
    "The intuition here is that while there is a *possibility* of winning in the second case, the probabilties of both are so small that subjects don't find them meaningful in the same way that the probabilities are meaningful in the same case.\n",
    "\n",
    "These results are all violations of the following implication of expected utility theory. If (y,pq) is preferred to (x,p), then (y,pqr) is preferred to (x,pr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Reflection Effect\"\n",
    "\n",
    "So far, we have only looked at violations of expected utility theory when the outcomes are all positive, what if there are negative outcomes?\n",
    "\n",
    "Kahneman and Tversky did the previous experiments with negative payoffs.\n",
    "\n",
    "| Positive Prospects    | Negative Prospects   | \n",
    "|:-----------------|:-----------------|\n",
    "| u((4000,.8))<u(3000) | u((-4000,.8))>u(-3000) |\n",
    "| u((4000,.2))>u((3000,.25)) | u((-4000,.2))<u((-3000, .25)) |\n",
    "| u((3000,.9))>u((6000,.45)) | u((-3000,.9))<u((-6000, .45)) |\n",
    "| u((3000,.002))<u((6000,.001)) | u((-3000,.002))>u((-6000, .001)) |\n",
    "\n",
    "The choices on the negative side were just the opposite compared to those on the positive side. On the surface, this makes sense. However there are some troubling implications.\n",
    "\n",
    "While the subjects are risk averse on the positive side, this inversion means that subjects are risk *seeking* on the negative side. For example, most subjects were willing to accept .8 chance of losing 4000 over the sure loss of 3000. In both the positive and negative domains, the subjects overweight certain outcomes, but in the former, it leads to risk aversion, in the latter, it leads to risk seeking.\n",
    "\n",
    "Importantly, both the positive and negative prospect experiments violate expected utility theory in the same manner as the detailed explanations above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Insurance Example (violation of concavity)\n",
    "\n",
    "Imagine that ther exists an insurance policy that you are indifferent between buying and not. Now imagine that the insurace is modified as such:\n",
    "\n",
    "1. You pay upfront half the original premium\n",
    "2. Half the time (let's say odd days of the month), if you experience an accident, you have to pay the other half of the premium and the insurer covers the damanages.\n",
    "3. The other half of the time (even days of the month), if you experience an accident, you get the premium you've paid upfront refunded, but you have to cover all damages.\n",
    "\n",
    "Would you purchase this new insurance if the original premium made you indifferent?\n",
    "\n",
    "80% of subjects said no.\n",
    "\n",
    "Let's examine the expected utilty prediction for this scenario. Say your current asset position is $w$. A potential damage would cause a loss of $x$ to $w$ with probability $p$. The indifference in preference for the original insurance that costs a premium of $y$ would be:\n",
    "\n",
    "$$\n",
    "pu(w-x)+(1-p)u(w)=u(w-y)\n",
    "$$\n",
    "\n",
    "Where the LHS is the expected utility of not owning insurance and the RHS is the expected utility from buying the insurance. If we reduce the premium by a factor of $r$ and the corresponding probability of coverage by $r$, we get the following expression:\n",
    "\n",
    "WLOG, let $u(w)=1$ and $u(w-x)=0$\n",
    "$$\n",
    "A = pu(w-x)+(1-p)u(w)=u(w-y)\\\\\n",
    "\\implies u(w-y)=1-p\\\\\n",
    "B = (1-p)u(w-ry)+rpu(w-y)+(1-r)u(w-x)\\\\\n",
    "\\implies B = (1-p)u(w-ry)+rp(1-p)\\\\\n",
    "\\implies B = (1-p)[u(w-ry)+rp] \\\\\n",
    "$$\n",
    "Concavity means that $u(\\alpha M+(1-\\alpha)N)>\\alpha u(M)+(1-\\alpha)u(N)$, i.e. the utility of the expected outcome is greater than the expected utilities of lottery.\n",
    "$$\n",
    "u(w-ry)=u((1-r)w+(r)(w-y))>(1-r)u(w)+ru(w-y) \\\\\n",
    "\\implies u(w-ry)>(1-r)+r(1-p)=(1-r+r-rp)=1-rp \\\\\n",
    "\\iff u(w-ry)>1-rp\\iff u(w-ry)+rp>1\\iff (1-p)[u(w-ry)+rp]>1-p\\\\\n",
    "\\iff (1-p)[u(w-ry)+rp]>u(w-y)\\\\\n",
    "\\iff B>A\n",
    "$$\n",
    "\n",
    "SO... given concavity of utility funcitons in expected utility theory, the preference should have been for probabilistic insurance over the original insurance plan. The experimental evidence suggests otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation effect\n",
    "\n",
    "Suppose there is a game such that there are 2 stages. In the first stage, there is a .75 probability of stopping the game without winning anything. In the second stage, there are 2 possible lotteries, one is (4000,.8) and the other is 3000 with certainty. In effect, this should be equivalent to $(4000, .25\\times.8=.2)$ and $(3000, .25)$.\n",
    "\n",
    "However, when this 2 stage lottery is presented to subjects, they picked (3000,.25) whereas most chose (4000,.25) when posed as a single stage lottery.\n",
    "\n",
    "Consider 2 more choices between lotteries\n",
    "\n",
    "You have been given $1000, now imagine which of the following you would pick.\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (1000, .5)| 500 |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "84% subjects picked B.\n",
    "\n",
    "Now imagine you have been given \\$2000 and are now pick one of the following\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (-1000, .5)| -500 |\n",
    "\n",
    "What would you pick?\n",
    "\n",
    "69% picked A.\n",
    "\n",
    "Note the 2 decisions are equivalent if you collapse to 1 stage. Both can be seen as:\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (2000, .5),(1000,.5)| 1500 |\n",
    "\n",
    "Again, the common component in the first stage is disregarded and the subjects make a choice based on the differences in the second stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prospect Theory\n",
    "\n",
    "Kahneman & Tversky characterize the decision making process by the following 2 stages:\n",
    "\n",
    "1. Editing\n",
    "    1. **Coding** - The experiments eem to suggest that people seem to distinguish between losses and gains rather than final states, i.e. Starting with 20k and losing 4000 vs losing 3000 should be different than starting with 0 and gaining 16k vs 17k. In the coding stage, the decision maker needs to define a neutral reference point. The outcomes are \"coded\" relative to this reference point.\n",
    "    2. **Combination** - Prospects can be simplified by combining probabilities with identical outcomes.\n",
    "    3. **Segregation** - Prospects might contain a riskless component that can be separated. For example, [(300,.8), (200,.2)] can be segragated into a surge gain of 200 and a lottery of (100,.2).\n",
    "    4. **Cancellation** - This is like the isolation effect. Common components of different prospects are disregarded. For example: $[(200,.2),(100,.5),(-50,.3)]$ and $[(200,.2),(150,.5),(-100,.3)]\\implies$ $[(100,.5),(-50,.3)]$ and $[(150,.5),(-100,.3)]$\n",
    "2. Evaluation - the decision maker then chooses between the edited lotteries.\n",
    "    1. Consumers make valuations, V, based on 2 components\n",
    "        1. Scale for probabilities, $\\pi$\n",
    "        2. Scale for outcomes, $v$\n",
    "    2. Combined, the valuation equation in prospect theory is:\n",
    "    $$\n",
    "    V((x,p), (y,q))= \\pi(p)v(x)+\\pi(q)v(y)\n",
    "    $$\n",
    "    3. We assume $v(0)=0$, $\\pi(0)=0$, and $\\pi(1)=1$\n",
    "\n",
    "**Prospect theory can be thought of as a generalization of expected utility theory.** Expected utility theory has $\\pi(p)=p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Typical value functions, $v$.\n",
    "\n",
    "Since the value functions in prospect theory measure valuations relative to a reference point, we describe value functions for positive and negative outcomes.\n",
    "\n",
    "For $x>0$:\n",
    "\n",
    "$$\n",
    "v''(x)<0\n",
    "$$\n",
    "\n",
    "In other words, the increase in v as x increases, is decreasing. This is as in expected utility theory. The value function is concave.\n",
    "\n",
    "For $x<0$:\n",
    "\n",
    "$$\n",
    "v''(x)>0\n",
    "$$\n",
    "\n",
    "This is different from expected utility theory. The value function is convex.\n",
    "\n",
    "In other words, the decreases in v as x decreases, is increasing. This is one of the core takeaways from prospect theory. Differences in symmetric losses vs. gains are valued more. \n",
    "\n",
    "![Loss Aversion Graphic](./Loss_Aversion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical probability functions, $\\pi$\n",
    "\n",
    "Recall the problem of choosing between $(6000, .001)$ and $(3000, .002)$. Most preferred the former lottery.\n",
    "\n",
    "In prospect theory form we have:\n",
    "$$\n",
    "\\pi(.001)v(6000)>\\pi(.002)v(3000)\\implies \\pi(.001)/\\pi(.002)>v(3000)/v(6000)>1/2\n",
    "$$\n",
    "\n",
    "The last inequality is due to concavity of $v$.\n",
    "\n",
    "This follows the **subaditivity** principle, e.g.\n",
    "\n",
    "$$\n",
    "\\pi(rp)>r\\pi(p) \n",
    "$$\n",
    "for $0<r<1$.\n",
    "\n",
    "This means that if we cut the probability by half, our probability weight, $\\pi$, is not cut by less than half. .001 seems more than 50% of .002. In fact, for many people, the 2 are almost equivalently \"unlikely.\" This seems to hold for small probability events.\n",
    "\n",
    "However, in larger probability problems such as the choice between $(6000, .)$ 45and $(3000, .90)$, the choices of subjects seem to suggest:\n",
    "\n",
    "$$\n",
    "\\pi(.45)v(6000)<\\pi(.90)v(3000)\\implies \\pi(.45)/\\pi(.90)<v(3000)/v(6000)>1/2\n",
    "$$\n",
    "\n",
    "This indicates that subadditivity does not necessarily need to hold for larger probabilities. In other words, we seem to think of the differences between .001 and .002 as negligible (even though one is twice as likely as the other) but we don't seem to underestimate the difference between .45 and .90 (one is also twice as large as the other here).\n",
    "\n",
    "Consider another decision between lotteries:\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (5000, .001)| 5 |\n",
    "\n",
    "82% chose A\n",
    "\n",
    "Now think about:\n",
    "\n",
    "| Prospect A | Prospect B | \n",
    "|:-------------|:-------------|\n",
    "| (-5000, .001)| -5 |\n",
    "\n",
    "83% chose B\n",
    "We tend overvalue the small probabilities, i.e. $\\pi(p)>p$ for small p.\n",
    "\n",
    "Recall the first examples of choices between lotteries: [(2500, .33), (2400, .66), (0, .01)] and 2400 for certain. Most chose the latter, thus:\n",
    "$$\n",
    "v(2400)>\\pi(.66)v(2400)+\\pi(.33)v(2500) \\\\\n",
    "\\implies [1-\\pi(.66)]v(2400)>\\pi(.33)v(2500)\n",
    "$$\n",
    "Now the second choice between lotteries: \n",
    "(2500, .33) and (2400, .34). Most chose the former, thus:\n",
    "$$\n",
    "\\pi(.33)v(2500)>\\pi(.34)v(2400)\n",
    "$$\n",
    "Combined, we get:\n",
    "$$\n",
    "[1-\\pi(.66)]v(2400)>\\pi(.33)v(2500)>\\pi(.34)v(2400) \\\\\n",
    "\\implies 1-\\pi(.66)>\\pi(.34) \\iff 1>\\pi(.34)+\\pi(.66)\n",
    "$$\n",
    "\n",
    "In other words we have **subcertainty**, i.e. the weights of all probabilities don't add up to 1.\n",
    "\n",
    "\n",
    "**Due to subadditivity, subcertainty, and thefact that we overweight small probabilities, the typical probability weight function looks like:**\n",
    "![Decision weight function](./decision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To conclude, the main differences between expected utility theory and prospect theory:\n",
    "\n",
    "1. We measure outcomes relative to a reference point.\n",
    "2. We edit choices following coding, combination, segregation, and cancellation\n",
    "3. We have weights for probabilities that are subadditive, subcertain, and overweighted for small probabilities.\n",
    "4. We are loss averse, i.e. have convex utilities for losses and concave utility for gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
